{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#problem1\n",
    "#define the function to compute optimal slope value \n",
    "def compute_slope_estimator(x, y):\n",
    "    x_bar = np.average(x)\n",
    "    y_bar = np.average(y)\n",
    "    n = x.shape[0]\n",
    "    numerator = np.dot(x, y) - n * x_bar * y_bar\n",
    "    denominator = np.dot(x, x) - n * np.square(x_bar)\n",
    "    \n",
    "    #calculate the optimal slope\n",
    "    a = numerator/denominator\n",
    "    return a \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#problem 2\n",
    "#define the function to compute the optimal intercept value\n",
    "def compute_intercept_estimator(x, y):\n",
    "    a = compute_slope_estimator(x, y)\n",
    "    x_bar = np.average(x)\n",
    "    y_bar = np.average(y)\n",
    "    \n",
    "    #calculate the optimal intercept\n",
    "    b = y_bar - a * x_bar\n",
    "    return b\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#problem 3\n",
    "#define the function to train model using input data\n",
    "def train_model(x, y):\n",
    "    a = compute_slope_estimator(x, y)\n",
    "    b = compute_intercept_estimator(x, y)\n",
    "    \n",
    "    tup = (a, b)\n",
    "    return tuple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#problem4\n",
    "#define the function to get y values from the generative model \n",
    "def sample_linear_model(x_vals, a, b, sd):\n",
    "    n = x_vals.shape[0]\n",
    "    y = np.zeros(n)\n",
    "    e = np.random.normal(0, sd, n)\n",
    "    \n",
    "    #get y's values \n",
    "    for i in range(n):\n",
    "        y[i] = a * x_vals[i] + b + e[i]\n",
    "        \n",
    "    #return y \n",
    "    return y\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#problem 5\n",
    "#define the function to get a list of n sampled datasets \n",
    "def sample_datasets(x_vals, a, b, sd, n):\n",
    "    ls = []\n",
    "    \n",
    "    #build the list of n datasets \n",
    "    for i in range(n):\n",
    "        y_vals = sample_linear_model(x_vals, a, b, sd)\n",
    "        ls.append(y_vals)\n",
    "    \n",
    "    #return the list of datasets // a list of arrays containing y values \n",
    "    return ls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#problem 6\n",
    "#define the function to compute the average estimated slope\n",
    "def compute_average_estimated_slope(x_vals):\n",
    "    ls_a = []\n",
    "    ls_y = sample_datasets(x_vals, 1, 1, 1, 1000)\n",
    "    \n",
    "    #compute the slope estimator\n",
    "    for i in range(1000):\n",
    "        a = compute_slope_estimator(x_vals, ls_y[i])\n",
    "        ls_a.append(a)\n",
    "        \n",
    "    \n",
    "    #compute the average of estimated slope\n",
    "    average_a = sum(ls_a)/len(ls_a)\n",
    "    \n",
    "    return average_a\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0114061344541867, 0.9874605062701537, 0.997760896755069]\n"
     ]
    }
   ],
   "source": [
    "#problem 7\n",
    "#compute the average estimated slope for different values of x_vals\n",
    "ls_a = []\n",
    "\n",
    "x_vals1 = np.linspace(0, 1, num=5)\n",
    "a1 = compute_average_estimated_slope(x_vals1)\n",
    "ls_a.append(a1)\n",
    "\n",
    "x_vals2 = np.linspace(0, 1, num=100)\n",
    "a2 = compute_average_estimated_slope(x_vals2)\n",
    "ls_a.append(a2)\n",
    "\n",
    "x_vals3 = np.linspace(0, 1, num=1000)\n",
    "a3 = compute_average_estimated_slope(x_vals3)\n",
    "ls_a.append(a3)\n",
    "\n",
    "print(ls_a)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Answer to question 7: When the number of x_vals increases, the estimated slope tend to \n",
    "#be closer to the true slope. The reason is that slope estimator tends to be more accurate\n",
    "#when n(number of x_vals) is large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#problem 8\n",
    "#define the functin to compute average squared error\n",
    "def compute_estimated_slope_error(x_vals):\n",
    "    ls_a = []\n",
    "    ls_squar = []\n",
    "    ls_y = sample_datasets(x_vals, 1, 1, 1, 1000)\n",
    "    \n",
    "    #compute the slope estimator\n",
    "    for i in range(1000):\n",
    "        a = compute_slope_estimator(x_vals, ls_y[i])\n",
    "        ls_a.append(a)\n",
    "        \n",
    "    \n",
    "    #compute the average squared error\n",
    "    for i in range(1000):\n",
    "        squar = (1 - ls_a[i]) * (1 - ls_a[i])\n",
    "        ls_squar.append(squar)\n",
    "    \n",
    "    average_squared_error_estimated_slope = sum(ls_squar)/len(ls_squar)\n",
    "    \n",
    "    return average_squared_error_estimated_slope\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.7833911557553839, 0.11205998808795474, 0.012399236484204147]\n"
     ]
    }
   ],
   "source": [
    "#problem 8 test with different values of x_vals\n",
    "ls_average_squared_error_estimated_slope = []\n",
    "\n",
    "x_vals1 = np.linspace(0, 1, num=5)\n",
    "a1 = compute_estimated_slope_error(x_vals1)\n",
    "ls_average_squared_error_estimated_slope.append(a1)\n",
    "\n",
    "x_vals2 = np.linspace(0, 1, num=100)\n",
    "a2 = compute_estimated_slope_error(x_vals2)\n",
    "ls_average_squared_error_estimated_slope.append(a2)\n",
    "\n",
    "x_vals3 = np.linspace(0, 1, num=1000)\n",
    "a3 = compute_estimated_slope_error(x_vals3)\n",
    "ls_average_squared_error_estimated_slope.append(a3)\n",
    "\n",
    "print(ls_average_squared_error_estimated_slope)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Answer to problem 8\n",
    "#As n increases, the average squared error decreases. The reason is that the estimators for slope and intercept\n",
    "#tends to be more accurate when the n(number of x_vals) is large. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#problem 9\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#first trial\n",
    "ls_a_1 = []               #create numpy to store estimated slope\n",
    "x_vals_1 = np.linspace(0, 1, num=5)     #try different size and values of x_vals\n",
    "ls_y_1 = sample_datasets(x_vals_1, 1, 1, 1, 1000)\n",
    "    \n",
    "#compute the slope estimator\n",
    "for i in range(1000):\n",
    "    a = compute_slope_estimator(x_vals_1, ls_y_1[i])\n",
    "    ls_a_1.append(a)\n",
    "\n",
    "    \n",
    "#second trial\n",
    "ls_a_2 = []               #create numpy to store estimated slope\n",
    "x_vals_2 = np.linspace(0, 1, num=100)   #try different size and values of x_vals\n",
    "ls_y_2 = sample_datasets(x_vals_2, 1, 1, 1, 1000)\n",
    "    \n",
    "#compute the slope estimator\n",
    "for i in range(1000):\n",
    "    a = compute_slope_estimator(x_vals_2, ls_y_2[i])\n",
    "    ls_a_2.append(a)\n",
    "\n",
    "    \n",
    "#third trial\n",
    "ls_a_3 = []               #create numpy to store estimated slope\n",
    "x_vals_3 = np.linspace(0, 1, num=1000)   #try different size and values of x_vals\n",
    "ls_y_3 = sample_datasets(x_vals_3, 1, 1, 1, 1000)\n",
    "    \n",
    "#compute the slope estimator\n",
    "for i in range(1000):\n",
    "    a = compute_slope_estimator(x_vals_3, ls_y_3[i])\n",
    "    ls_a_3.append(a)\n",
    "\n",
    "     \n",
    "    \n",
    "#draw the histogram\n",
    "array_a_1 = np.array(ls_a_1)\n",
    "plt.hist(array_a_1)\n",
    "plt.show()\n",
    "plt.savefig(\"9_1.png\")\n",
    "    \n",
    "array_a_2 = np.array(ls_a_2)\n",
    "plt.hist(array_a_2)\n",
    "plt.show()\n",
    "plt.savefig(\"9_2.png\")\n",
    "\n",
    "array_a_3 = np.array(ls_a_3)\n",
    "plt.hist(array_a_3)\n",
    "plt.show()    \n",
    "plt.savefig(\"9_3.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Answer to problem 9:\n",
    "#As number of x_vals increases, more slope estimates concentrate around\n",
    "#the true slope which is 1. The reason is that slope estimator tends to be more accurate when n(number of x_vals)\n",
    "#is large "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Problem10\n",
    "#define function to calculate prediction error\n",
    "def calculate_prediction_error(y, y_hat):\n",
    "    n = y.shape[0]      #get the size of the array\n",
    "    \n",
    "    #calculate the prediction error\n",
    "    ls_squar = []\n",
    "    \n",
    "    for i in range(n):\n",
    "        squar = (y[i] - y_hat[i]) * (y[i] - y_hat[i])\n",
    "        ls_squar.append(squar)\n",
    "\n",
    "    prediction_error = sum(ls_squar)/n\n",
    "    \n",
    "    return prediction_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Problem 11\n",
    "#define the function to calculate the average training set error\n",
    "def average_training_set_error(x_vals):\n",
    "    ls_y = sample_datasets(x_vals, 1, 1, 1, 1000)  #sample y\n",
    "    ls_y_hat = []        #list to store estimated y\n",
    "    ls_a_hat = []        #list to store slope estimator\n",
    "    ls_b_hat = []        #list to store intercept estimator\n",
    "    \n",
    "    #compute slope and intercept estimator\n",
    "    for i in range(1000):\n",
    "        a_hat = compute_slope_estimator(x_vals, ls_y[i])\n",
    "        b_hat = compute_intercept_estimator(x_vals, ls_y[i])\n",
    "        ls_a_hat.append(a_hat)     #store slope estimator\n",
    "        ls_b_hat.append(b_hat)    #store intercept estimator\n",
    "    \n",
    "    #compute estimated y\n",
    "    n = x_vals.shape[0]\n",
    "    for i in range(1000):\n",
    "        ls_y_hat_sub = []\n",
    "        for j in range(n):\n",
    "            y_hat = ls_a_hat[i] * x_vals[j] + ls_b_hat[i]\n",
    "            ls_y_hat_sub.append(y_hat)\n",
    "        \n",
    "        array_y_hat = np.array(ls_y_hat_sub)\n",
    "        ls_y_hat.append(array_y_hat)\n",
    "    \n",
    "    \n",
    "    #calculate prediction error\n",
    "    ls_pi = []              #list to store pi\n",
    "    for i in range(1000):\n",
    "        prediction_error = calculate_prediction_error(ls_y[i], ls_y_hat[i])\n",
    "        ls_pi.append(prediction_error)\n",
    "        \n",
    "    average_error = sum(ls_pi)/len(ls_pi)\n",
    "    return average_error\n",
    "    \n",
    "        \n",
    "    \n",
    "            \n",
    "    \n",
    "       \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6037663117545249\n",
      "0.973100141204567\n",
      "0.9978066036397112\n"
     ]
    }
   ],
   "source": [
    "#Problem 11\n",
    "#first trial \n",
    "x_vals = np.linspace(0, 1, num = 5)\n",
    "print(average_training_set_error(x_vals))\n",
    "\n",
    "#second trial \n",
    "x_vals = np.linspace(0, 1, num = 100)\n",
    "print(average_training_set_error(x_vals))\n",
    "\n",
    "\n",
    "#third trial \n",
    "x_vals = np.linspace(0, 1, num = 1000)\n",
    "print(average_training_set_error(x_vals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Answer to problem 11\n",
    "#As number of elements in x_vals increases, the average prediction error approaches 1. The reason is that when we \n",
    "#sample from y, we set the error's standard deviation to 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the function to calculate the average value of the errors \n",
    "#by testing the linear model against data other than those used to \n",
    "#build the model\n",
    "#output a single value of average value of the errors \n",
    "\n",
    "\n",
    "def average_test_set_error(x_vals):\n",
    "    ls_y = sample_datasets(x_vals, 1, 1, 1, 1000)  #sample y\n",
    "    ls_y_hat = []        #list to store estimated y\n",
    "    ls_a_hat = []        #list to store slope estimator\n",
    "    ls_b_hat = []        #list to store intercept estimator\n",
    "    \n",
    "    #compute slope and intercept estimator\n",
    "    for i in range(1000):\n",
    "        a_hat = compute_slope_estimator(x_vals, ls_y[i])\n",
    "        b_hat = compute_intercept_estimator(x_vals, ls_y[i])\n",
    "        ls_a_hat.append(a_hat)     #store slope estimator\n",
    "        ls_b_hat.append(b_hat)    #store intercept estimator\n",
    "    \n",
    "    #compute estimated y\n",
    "    n = x_vals.shape[0]\n",
    "    for i in range(1000):\n",
    "        ls_y_hat_sub = []\n",
    "        for j in range(n):\n",
    "            y_hat = ls_a_hat[i] * x_vals[j] + ls_b_hat[i]\n",
    "            ls_y_hat_sub.append(y_hat)\n",
    "        \n",
    "        array_y_hat = np.array(ls_y_hat_sub)\n",
    "        ls_y_hat.append(array_y_hat)\n",
    "    \n",
    "    \n",
    "    #sample a test set\n",
    "    array_y_test = sample_linear_model(x_vals, 1, 1, 1)\n",
    "    ls_pi = []    #list to store pi\n",
    "    for i in range(1000):\n",
    "        prediction_error = calculate_prediction_error(array_y_test, ls_y_hat[i])\n",
    "        ls_pi.append(prediction_error)\n",
    "        \n",
    "    average_error = sum(ls_pi)/len(ls_pi)\n",
    "    return average_error\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5291212252067559\n",
      "0.9891674776952099\n",
      "0.9654747830725254\n"
     ]
    }
   ],
   "source": [
    "#Problem 12\n",
    "#first trial \n",
    "x_vals = np.linspace(0, 1, num = 5)\n",
    "print(average_test_set_error(x_vals))\n",
    "\n",
    "#second trial \n",
    "x_vals = np.linspace(0, 1, num = 100)\n",
    "print(average_test_set_error(x_vals))\n",
    "\n",
    "\n",
    "#third trial \n",
    "x_vals = np.linspace(0, 1, num = 1000)\n",
    "print(average_test_set_error(x_vals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The test set prediction error is more random than the average training\n",
    "#set prediction error. The average test set prediction error sometimes is \n",
    "#larger than 1, and sometimes is smaller than 1. The reason is that we \n",
    "#test our models on the test set instead of training set.\n",
    "#As the number of elements in x_vals increases, the average test set prediction\n",
    "#error generally tends to 1. The reason is that we set the standard deviation \n",
    "#to 1 when we sample from y and the estimator tends to be more accurate when\n",
    "#n(number of x_vals) is large. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:lign167]",
   "language": "python",
   "name": "conda-env-lign167-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
